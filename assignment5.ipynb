{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "assignment5.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictoriaRe/HSE-DataScience/blob/master/assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZJ9R6wo0Dwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y8uSMXY1pGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlZh6Wf0DxM",
        "colab_type": "code",
        "outputId": "f253ddaa-1f07-4716-9b6f-4f77e4ee2ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('imdb_master.csv', encoding = 'latin-1')\n",
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "      <td>0_2.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10000_4.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10001_1.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10002_3.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10003_3.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  type  ... label         file\n",
              "0           0  test  ...   neg      0_2.txt\n",
              "1           1  test  ...   neg  10000_4.txt\n",
              "2           2  test  ...   neg  10001_1.txt\n",
              "3           3  test  ...   neg  10002_3.txt\n",
              "4           4  test  ...   neg  10003_3.txt\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM8PktqZ0Dxg",
        "colab_type": "code",
        "outputId": "71eb8a60-447d-4333-8174-ce3b864251e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "df_test = df[df['type']=='test'].drop(['Unnamed: 0','type','file'],axis=1)\n",
        "df_train = df[df['type']=='train'].drop(['Unnamed: 0','type','file'],axis=1)\n",
        "len(df_test), len(df_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 75000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkU1S7cU0Dxw",
        "colab_type": "code",
        "outputId": "2758f688-8b0d-4b32-a393-285ebaaf4afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25000</th>\n",
              "      <td>Story of a man who has unnatural feelings for ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25001</th>\n",
              "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25002</th>\n",
              "      <td>This film lacked something I couldn't put my f...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25003</th>\n",
              "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25004</th>\n",
              "      <td>When I was little my parents took me along to ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review label\n",
              "25000  Story of a man who has unnatural feelings for ...   neg\n",
              "25001  Airport '77 starts as a brand new luxury 747 p...   neg\n",
              "25002  This film lacked something I couldn't put my f...   neg\n",
              "25003  Sorry everyone,,, I know this is supposed to b...   neg\n",
              "25004  When I was little my parents took me along to ...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyBuQS960Dx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train[df_train['label'] != 'unsup']\n",
        "df_test = df_test[df_test['label'] != 'unsup']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0RvKdXP0DyG",
        "colab_type": "code",
        "outputId": "e8deb02f-aca2-4b25-95bd-f37a892c646e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "len(df_test), len(df_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2VEdUqm0DyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['label'] = df_train['label'].apply(lambda x : 0 if x=='neg' else 1)\n",
        "df_test['label'] = df_test['label'].apply(lambda x : 0 if x=='neg' else 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcBwvPlG0DyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "939b4153-7f85-4cca-9986-ba5c7c28324c"
      },
      "source": [
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScmWxmiR0DyZ",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkej8d-_0Dyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "e44b71a6-df46-4abe-b626-0a814af199d4"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
        "#     lower letters\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "#     delete stopwords\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n",
        "df_train['processed'] = df_train.review.apply(lambda x: preprocess(x))\n",
        "df_test['processed'] = df_test.review.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deNDFjay0Dyg",
        "colab_type": "text"
      },
      "source": [
        "# Deep Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96yarYBr0Dyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "max_features = 10000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(df_train['processed'])\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(df_train['processed'])\n",
        "\n",
        "maxlen = 150\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "y = df_train['label']\n",
        "\n",
        "embed_size = 256\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_size))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(40, activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUP_MB3e0Dyo",
        "colab_type": "code",
        "outputId": "b33faf91-51f9-4364-a0be-2e8318bba27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "20000/20000 [==============================] - 177s 9ms/step - loss: 0.4586 - acc: 0.7713 - val_loss: 0.5704 - val_acc: 0.7540\n",
            "Epoch 2/3\n",
            "20000/20000 [==============================] - 174s 9ms/step - loss: 0.2083 - acc: 0.9220 - val_loss: 0.5850 - val_acc: 0.7588\n",
            "Epoch 3/3\n",
            "20000/20000 [==============================] - 175s 9ms/step - loss: 0.1241 - acc: 0.9575 - val_loss: 0.9844 - val_acc: 0.6734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e08d84da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0MGwkLk0Dyv",
        "colab_type": "text"
      },
      "source": [
        "### Check accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDDwtJVr0Dyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(df_test['processed'])\n",
        "maxlen = 150\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELY7XnFx0Dy1",
        "colab_type": "code",
        "outputId": "8130aee5-cb0c-4c31-ce74-ea693409b776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>0</td>\n",
              "      <td>mr costner ha drag movie far longer necessary ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>0</td>\n",
              "      <td>example majority action film generic bore real...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>0</td>\n",
              "      <td>first hate moronic rapper couldnt act gun pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>0</td>\n",
              "      <td>even beatles could write song everyone like al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>0</td>\n",
              "      <td>brass picture movie fit word really somewhat b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                          processed\n",
              "0  Once again Mr. Costner has dragged out a movie...  ...  mr costner ha drag movie far longer necessary ...\n",
              "1  This is an example of why the majority of acti...  ...  example majority action film generic bore real...\n",
              "2  First of all I hate those moronic rappers, who...  ...  first hate moronic rapper couldnt act gun pres...\n",
              "3  Not even the Beatles could write songs everyon...  ...  even beatles could write song everyone like al...\n",
              "4  Brass pictures (movies is not a fitting word f...  ...  brass picture movie fit word really somewhat b...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmCHTwG00Dy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take_pred(x):\n",
        "    if x>=0.5:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "preds = [take_pred(x[0]) for x in model.predict(X_test)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beaLtspO0DzA",
        "colab_type": "code",
        "outputId": "6add584f-dfa3-47dd-b46a-8df50c8bda23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "(preds == df_test['label'].values).mean()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywR97PJV0DzF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### Получили 83% точности! Но мы видим, что сеть переобучается(судя по скору val_accuracy). Давайте попробуем сделаем сеть попроще."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFj9sqd90DzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 5000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(df_train['processed'])\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(df_train['processed'])\n",
        "\n",
        "maxlen = 100\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "y = df_train['label']\n",
        "\n",
        "embed_size = 128\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_size))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEtSO2NH0DzL",
        "colab_type": "code",
        "outputId": "663aebf3-9e93-46ad-d796-c627eebb8051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "20000/20000 [==============================] - 63s 3ms/step - loss: 0.5391 - acc: 0.7134 - val_loss: 0.4860 - val_acc: 0.7976\n",
            "Epoch 2/3\n",
            "20000/20000 [==============================] - 61s 3ms/step - loss: 0.2725 - acc: 0.8921 - val_loss: 0.5124 - val_acc: 0.7798\n",
            "Epoch 3/3\n",
            "20000/20000 [==============================] - 61s 3ms/step - loss: 0.2013 - acc: 0.9255 - val_loss: 0.5932 - val_acc: 0.7590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0dcf4e3518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8F_V8vd0DzS",
        "colab_type": "text"
      },
      "source": [
        "### Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2EkywLk0DzT",
        "colab_type": "code",
        "outputId": "906a68bb-3903-41da-f44d-d182a9e1c675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(df_test['processed'])\n",
        "maxlen = 100\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
        "preds = [take_pred(x[0]) for x in model.predict(X_test)]\n",
        "(preds == df_test['label'].values).mean()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teUGBWtm0DzY",
        "colab_type": "text"
      },
      "source": [
        "## Получилось лучше: 85%. Попробуем использовать unsupervised dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29FuSBQt0Dza",
        "colab_type": "text"
      },
      "source": [
        "##### Что мы сделаем? Классифицируем unsupervised с помощью старой модели и обучем по-новому"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzWaXMuC0Dzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_unsup = df[df['type']=='train'].drop(['Unnamed: 0','type','file'],axis=1)\n",
        "df_unsup = df_unsup[df_unsup['label'] == 'unsup']\n",
        "\n",
        "df_unsup['label'] = df_unsup['label'].apply(lambda x : 0 if x=='neg' else 1)\n",
        "df_unsup['processed'] = df_unsup.review.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncOry5Kd0Dze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_tokenized_unsup = tokenizer.texts_to_sequences(df_unsup['processed'])\n",
        "maxlen = 100\n",
        "X_unsup = pad_sequences(list_tokenized_unsup, maxlen=maxlen)\n",
        "df_unsup['label'] = [take_pred(x[0]) for x in model.predict(X_unsup)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRTctHRa0Dzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_new = pd.concat([df_unsup, df_train]).reset_index(drop=True)\n",
        "\n",
        "max_features = 10000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(df_new['processed'])\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(df_new['processed'])\n",
        "\n",
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "y = df_new['label']\n",
        "\n",
        "embed_size = 256\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_size))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(40, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKWJANUD0Dzn",
        "colab_type": "code",
        "outputId": "48f621cf-5a64-49c3-e3a0-e35cb97b6c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 15000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 1237s 21ms/step - loss: 0.3148 - acc: 0.8573 - val_loss: 0.3494 - val_acc: 0.8599\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 1237s 21ms/step - loss: 0.1621 - acc: 0.9357 - val_loss: 0.4488 - val_acc: 0.8357\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 1239s 21ms/step - loss: 0.1303 - acc: 0.9493 - val_loss: 0.9078 - val_acc: 0.6949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0dc311df60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK8fM1rU0Dzr",
        "colab_type": "text"
      },
      "source": [
        "### Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFHDsptL0Dzs",
        "colab_type": "code",
        "outputId": "353538f4-715c-46e4-e6d4-4ed12af26925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(df_test['processed'])\n",
        "maxlen = 100\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
        "preds = [take_pred(x[0]) for x in model.predict(X_test)]\n",
        "(preds == df_test['label'].values).mean()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7878"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSOXQIGa0Dzw",
        "colab_type": "code",
        "outputId": "589f84ac-a624-4104-dbcc-2ff5bdbf2741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "c = 0\n",
        "for i in range(len(df_test)):\n",
        "    if df_test.loc[i, 'label'] != preds[i]:\n",
        "        print(df_test.loc[i, 'processed'])\n",
        "        print(' ---------------------------------- ')\n",
        "        c += 1\n",
        "    if (c == 10):\n",
        "        break"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "think would appropriate title film since pad hell back stock footage various bug animal recently find prey original vhs big box form wa excite love find old slasher film vhs cover artwork fantastic usually though turn film le fantastic prey one filmsbr br fair start ok killer stalk clichã teenager wood heartbeat sound use great effect make tense watch film basically big fat clichã campfire story section roll film take new direction spend almost half run time backstory killer actually think wa quite original idea however backstory end abruptly show u stockfootage burn woodland lack budget really start show now). this, return dumb teenager pick woods. killer show end, shame actually make effective look killer. sort like cropsy burning, better. gore, much, although there's ok face squish moment end. <br /><br />overall, recommend film anyone slasher completists - really big mess.\n",
            " ---------------------------------- \n",
            "one strange selfimportant selfindulgent movie try hard profound isnt instead spout cliche try pas profundity typical scene peter kelsey grammer explain protagonist best friend adam dwier brown man start life breast feed move suck breast girlfriend finally wife thus conclude ultimately life suck deep treat variety character offer perspective life universe etc adam travel mojave desert foot abruptly leaf la day wed family friend fiance assume dead car wa find military test range smash rocket character entertain others best far escapee mental hospital speak voice others. actor, jam kevin ward, doe great impressions, include nicholson, popeye, several character original star trek. interest character leave screen, we're stick adam pursuit profound. long trip, drag many places. fact, longest hour half movie i've ever seen. finale hardly make seem worth while, all.<br /><br />i discover movie play hbo one day wake early click tv. learn me. next time i'll try harder sleep in.\n",
            " ---------------------------------- \n",
            "caution spoiler end movie announce bridge collapse day wa capture impression attack wa nothing reality take bridge remagen wa last important victory western ally wa cross rhine ally try achieve six month remagen bridge wa take war end weeksbr br bridge need last day wa capture wa enough time american send combat engineer large protective force side could start build series pontoon bridge take bridge wa complete success mean end war wa near would last summer contrary cynical nature film victory wa herald elation troop know vital battle wasbr br film ha little real history wa reflection cynical nature time wa produce\n",
            " ---------------------------------- \n",
            "cant go long describe tittle simply feel strong read comment see proud patriotic frenchman seem like thats saybr br bore long sometimes even stupidbr br p 74 10 viewer must go crazybr br cant go long describe tittle, simply feel strong it. read comment see proud patriotic frenchman seem like it, that's say...<br /><br />boring long sometimes even stupid...<br /><br />p.s. 7.4 10, viewer must go crazy\n",
            " ---------------------------------- \n",
            "enjoy prequels find relationship tucker chan previously hilarious rh3 however wa rehash first two without charm humor think may laugh  wa ng tucker wa exceedingly annoy film character didnt seem purpose bungle everything irritate way possible chan always likable seem tire film wa able predict everything  villain wa girl wa spoiler alert goodguyturnedbadguy wa etc hope see movie tucker chan separate endeavor rush hour sequel tire recommend rental purchase\n",
            " ---------------------------------- \n",
            "parent may enjoy show fail find humor funny dentist husband impregnate hygienist assistant oldest daughter get impregnate captain high school football team absolutely nothing shock sometimes people think constitute humor nowadays blame show like date game newlywed game bring issue sex forefront mid1960s sure series ha touch moment still thats excuse content otherwise go series nothing like familyoriented day love lucy five decade br br answer would series play lifetime cable channel channel brass think woman relate rebas character absolutely dislike character reba hart daughter kyra best describe ditsy bitter teenager! funny, wonder actress play kyra; scarlett pomers, like real life away acting. play blockhead ex-husband dentist, christopher rich, much better. barbara jean, play melissa peterman, ditsy herself! character van cheyenne also annoying.<br /><br />something else baffle dingbat-of-a-series creator, allison m. gibson, decide set series live 25 mile away from; houston, texas! reba mcentire even state, oklahoman! one season decide make incidental music sound like pig snorting? mean hear baritone saxophone play drum accompany it, melody basically tuneless!\n",
            " ---------------------------------- \n",
            "friend rent one night ago must say single best movie ever see mean woah dude better get brew joint close dude lindas wearin bra poetry woah wonderfuly original movie mean dont usually find slasher film every single murder exactly mean exactly thats originality almost transition scene great closeup psycho er scrub cool act wonderful dad wa brilliant must study real dad filming. many movie find make sense? many. one gems. mean, cool one guy wait outside like six hour pull prank, friend inside? that's really cool. overall i'd say single greatest film genre, nay, world! *****\n",
            " ---------------------------------- \n",
            "okay know bore cophomicide tv show come believe trace back movie scene crime feel like tv episode episode serial complete stock character situation  hotshot cop clash superior age cop doesnt want desk job despite fail eyesight reckless rookie doublecrossing dame etcbr br like many actor good job overall find movie dull im fan genre. keep tune discuss case ...something bookie informers. oh yeah, wa stripper, play previously wholesome gloria dehaven. want know is: keep call van johnson \"uncle wiggly\"? uncle wiggly rabbit? character children's book? heck doe anything? guess get tough-guy film noir-ish kinda jargon.<br /><br />in fact, much dialogue make mutter \"nobody talk like that!\" however, could relate one scene cop's wife (arlene dahl), worry every time go work, realize maybe make husband center life. yeah, know feel love someone much, dependent them, there's constant fear safety. moment truth film, underneath stylize dialogue atmosphere try self-consciously gritty real, actually seem unreal me.<br /><br />a little background: movie wa make dore schary take mgm louis b. mayer, begin put end wholesome musical make mgm great. dore schary wa determine bring \"realism\" movies. kinda hate dore schary. maybe blame pretentious, bleak movie make today, wallow ugly \"truths\" life, focus (and, opinion, help perpetuate) worst humanity rather best. longer uplift u way classic movie design - provide necessary distraction great depression world war ii.<br /><br />well, damn it, still need kind distraction today! there's still plenty depression plenty war. people turn nowadays want escape? trashy, brain-deadening reality tv. thank lot, dore!\n",
            " ---------------------------------- \n",
            "many spooky western make 30 early 40 although ha strong begin isnt one randy bower john wayne stop halfway house saloon find full dead body bartender corpse drape bar hold gun eye watch randy behind hole cut eye picture player piano play loveliest night year br br wa result robbery marvin black gang get ed rogers 30000 randy investigator work alone waste little time get arrested, escape (with ed's daughter sally's help) literally land midst black gang's hideout behind waterfall. move along fairly quickly. one many chase randy slow down.<br /><br />we even get george hayes, clean shave play two parts-- marvin black, vilest villain, well good citizen, matt mute, communicate via handwritten messages. play two opposite role wa good idea, write message thing get old real fast, even him, finally give near end say sally, \"ah, i'm feed this!\" find george play vile, vile, double cross villain serial \"the lose city\" (1934).<br /><br />i think 'lone star' film title relate to, mention film! sally offer hand randy says, \"he's alone anymore!\" cut arm around look face lake. sally's run randy seem abrupt sufficiently prepare for. much time spend horseback escape sheriff.<br /><br />not bad consider everything, great either. i'd really give 4 half.\n",
            " ---------------------------------- \n",
            "movie happy lullaby wa make make u sleep thatâs dream top beautiful natasha henstridge screenplay deep character nothing special letâs sleep\n",
            " ---------------------------------- \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3svzwvUd0Dz0",
        "colab_type": "code",
        "outputId": "f8d24325-2c49-4492-e58c-490a08f4deb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "model.fit(X_t,y, batch_size=batch_size, epochs=3, validation_split=0.2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 15000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 1240s 21ms/step - loss: 0.1149 - acc: 0.9553 - val_loss: 0.7251 - val_acc: 0.7935\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 1246s 21ms/step - loss: 0.0755 - acc: 0.9719 - val_loss: 0.5777 - val_acc: 0.8451\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 1249s 21ms/step - loss: 0.0556 - acc: 0.9796 - val_loss: 0.7081 - val_acc: 0.8320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0dc29b55f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMYa5gJT0Dz5",
        "colab_type": "text"
      },
      "source": [
        "### Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7awy3t-0Dz_",
        "colab_type": "code",
        "outputId": "e51d2f05-aa0e-4420-9368-32cbb8ae309a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "preds = [take_pred(x[0]) for x in model.predict(X_test)]\n",
        "(preds == df_test['label'].values).mean()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YwSOxui0D0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}